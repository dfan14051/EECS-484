{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init_var = tf.global_variables_initializer()\n",
    "sess.run(init_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.         4.         1.         1.         0.65765766 0.25\n",
      "  1.         0.8        0.         0.57142857 0.40765391 1.        ]\n",
      " [7.         4.         1.         3.         0.65765766 0.25\n",
      "  0.93366093 0.         1.         1.         0.66139767 0.5       ]]\n",
      "[0.33097762 0.26266196]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "inputs = np.genfromtxt ('basf_inputs_rand_normalized.csv', delimiter=\",\")\n",
    "targets = np.genfromtxt ('basf_targets_rand_normalized.csv', delimiter=\",\")\n",
    "\n",
    "print(inputs[0:2, :])\n",
    "print(targets[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 1029\n",
      "(1029, 12)\n",
      "[[3.         4.         1.         1.         0.65765766 0.25\n",
      "  1.         0.8        0.         0.57142857 0.40765391 1.        ]\n",
      " [7.         4.         1.         3.         0.65765766 0.25\n",
      "  0.93366093 0.         1.         1.         0.66139767 0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "data = inputs\n",
    "\n",
    "print(\"Number of examples: %i\" % n)\n",
    "print(data.shape)\n",
    "print(data[0:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.5714286  0.4076539  1.        ]\n",
      " [0.         0.         0.         ... 1.         0.6613977  0.5       ]\n",
      " [0.         0.         1.         ... 0.5714286  0.7121464  0.33333334]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.71428573 0.36439267 1.        ]\n",
      " [0.         0.         0.         ... 0.5714286  0.42845258 0.33333334]\n",
      " [0.         1.         0.         ... 0.5714286  0.68053246 0.5       ]]\n",
      "(1029, 25)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_onehot(data):\n",
    "    one_hots = []\n",
    "    for i in range(4):\n",
    "        depth = np.max(data[:, i])\n",
    "        indicies = data[:, i]\n",
    "        casted_indicies = tf.cast(indicies, tf.int32)\n",
    "        one_hot = tf.one_hot(casted_indicies, depth)\n",
    "        one_hots.append(one_hot)\n",
    "    concat_one_hot = tf.concat(one_hots[:], 1)\n",
    "    onehot_data = tf.concat([concat_one_hot, data[:, 4:]], 1)\n",
    "    print(sess.run(onehot_data))\n",
    "    print(onehot_data.shape)\n",
    "    return onehot_data\n",
    "    \n",
    "onehot_data = convert_to_onehot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 25)\n",
      "(200, 25)\n",
      "(29, 25)\n",
      "[[0.        0.        0.        1.        0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  1.        0.        0.        0.6576577 0.25      1.        0.8\n",
      "  0.        0.5714286 0.4076539 1.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  1.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        1.        0.6576577 0.25      0.9336609 0.\n",
      "  1.        1.        0.6613977 0.5      ]]\n",
      "[[0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.\n",
      "  1.         0.         1.         0.         0.         0.53783786\n",
      "  1.         0.8108108  0.8        0.         0.5714286  0.39767054\n",
      "  0.75      ]\n",
      " [0.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         0.         1.         0.\n",
      "  0.         0.         0.         0.         1.         0.5315315\n",
      "  0.25       0.9336609  0.8        0.         0.5714286  0.6647255\n",
      "  0.5       ]]\n",
      "[[0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.\n",
      "  1.         0.         0.         0.         0.         0.3963964\n",
      "  0.375      0.9336609  0.8        0.         0.5714286  0.39351082\n",
      "  0.75      ]\n",
      " [0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.         0.         0.6216216\n",
      "  1.         1.         0.8        0.         0.5714286  0.4359401\n",
      "  0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "training_x = onehot_data[0:800, :]\n",
    "training_y = targets[0:800]\n",
    "validation_x = onehot_data[800:1000, :]\n",
    "validation_y = targets[800:1000]\n",
    "test_x = onehot_data[1000:, :]\n",
    "test_y = targets[1000:]\n",
    "\n",
    "print(training_x.shape)\n",
    "print(validation_x.shape)\n",
    "print(test_x.shape)\n",
    "\n",
    "print(sess.run(training_x[0:2, :]))\n",
    "print(sess.run(validation_x[0:2, :]))\n",
    "print(sess.run(test_x[0:2, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 799 samples, validate on 199 samples\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 0s 6ms/step - loss: 0.0611 - val_loss: 0.0486\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 753us/step - loss: 0.0418 - val_loss: 0.0472\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 737us/step - loss: 0.0406 - val_loss: 0.0461\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 711us/step - loss: 0.0397 - val_loss: 0.0452\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 695us/step - loss: 0.0389 - val_loss: 0.0442\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 687us/step - loss: 0.0380 - val_loss: 0.0432\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 680us/step - loss: 0.0372 - val_loss: 0.0421\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 690us/step - loss: 0.0363 - val_loss: 0.0409\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 673us/step - loss: 0.0354 - val_loss: 0.0397\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 685us/step - loss: 0.0345 - val_loss: 0.0385\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 688us/step - loss: 0.0335 - val_loss: 0.0372\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 684us/step - loss: 0.0324 - val_loss: 0.0358\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 675us/step - loss: 0.0313 - val_loss: 0.0344\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 684us/step - loss: 0.0302 - val_loss: 0.0330\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 691us/step - loss: 0.0290 - val_loss: 0.0316\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 695us/step - loss: 0.0278 - val_loss: 0.0301\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 685us/step - loss: 0.0266 - val_loss: 0.0285\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 707us/step - loss: 0.0253 - val_loss: 0.0271\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 692us/step - loss: 0.0241 - val_loss: 0.0256\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 694us/step - loss: 0.0230 - val_loss: 0.0242\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 691us/step - loss: 0.0218 - val_loss: 0.0228\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 692us/step - loss: 0.0205 - val_loss: 0.0213\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 691us/step - loss: 0.0192 - val_loss: 0.0198\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 696us/step - loss: 0.0179 - val_loss: 0.0183\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 677us/step - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 673us/step - loss: 0.0152 - val_loss: 0.0154\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 680us/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 675us/step - loss: 0.0124 - val_loss: 0.0127\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 680us/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 730us/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 728us/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 695us/step - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 672us/step - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 684us/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 673us/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 707us/step - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 686us/step - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 693us/step - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 700us/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 699us/step - loss: 0.0056 - val_loss: 0.0066\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 686us/step - loss: 0.0055 - val_loss: 0.0065\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 696us/step - loss: 0.0077 - val_loss: 0.0109\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 692us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 683us/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 683us/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 672us/step - loss: 0.0059 - val_loss: 0.0064\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 667us/step - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 664us/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 663us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 699us/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 721us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 744us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 692us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 684us/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 679us/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 680us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 672us/step - loss: 0.0050 - val_loss: 0.0057\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 684us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 678us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 690us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 696us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 698us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 694us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 700us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 700us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 684us/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 692us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 691us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 680us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 669us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 678us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 672us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 661us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 664us/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 667us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 668us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 670us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 670us/step - loss: 0.0040 - val_loss: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 666us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 671us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 722us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 734us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 667us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 668us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 666us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 686us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 669us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 669us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 706us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 703us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 709us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 711us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 693us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 670us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 666us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 668us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 668us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 674us/step - loss: 0.0035 - val_loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=25))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "sgd = SGD(lr=0.1)\n",
    "model.compile(sgd, loss='mean_squared_error')\n",
    "history = model.fit(training_x, training_y, validation_data=(validation_x, validation_y), validation_steps=10, steps_per_epoch=44, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 473us/step\n",
      "MSE: 0.00411713\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: %.8f\" % model.evaluate(test_x, test_y, steps=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = onehot_data[0:750, :]\n",
    "training_y = targets[0:750]\n",
    "validation_x = onehot_data[750:1000, :]\n",
    "validation_y = targets[750:1000]\n",
    "test_x = onehot_data[1000:, :]\n",
    "test_y = targets[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0419 - val_loss: 0.0418\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 772us/step - loss: 0.0391 - val_loss: 0.0406\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 704us/step - loss: 0.0380 - val_loss: 0.0396\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 705us/step - loss: 0.0371 - val_loss: 0.0387\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 691us/step - loss: 0.0362 - val_loss: 0.0378\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 685us/step - loss: 0.0353 - val_loss: 0.0369\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 677us/step - loss: 0.0344 - val_loss: 0.0360\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 678us/step - loss: 0.0334 - val_loss: 0.0350\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 688us/step - loss: 0.0325 - val_loss: 0.0341\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 697us/step - loss: 0.0315 - val_loss: 0.0330\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 676us/step - loss: 0.0305 - val_loss: 0.0319\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 689us/step - loss: 0.0295 - val_loss: 0.0309\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 685us/step - loss: 0.0284 - val_loss: 0.0298\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 686us/step - loss: 0.0273 - val_loss: 0.0287\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 697us/step - loss: 0.0262 - val_loss: 0.0275\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 704us/step - loss: 0.0250 - val_loss: 0.0263\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 682us/step - loss: 0.0237 - val_loss: 0.0251\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 688us/step - loss: 0.0224 - val_loss: 0.0238\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 698us/step - loss: 0.0210 - val_loss: 0.0223\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 692us/step - loss: 0.0197 - val_loss: 0.0208\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 685us/step - loss: 0.0184 - val_loss: 0.0194\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 685us/step - loss: 0.0171 - val_loss: 0.0180\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 692us/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 698us/step - loss: 0.0146 - val_loss: 0.0152\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 681us/step - loss: 0.0133 - val_loss: 0.0138\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 675us/step - loss: 0.0122 - val_loss: 0.0125\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 668us/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 664us/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 664us/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 653us/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 665us/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 666us/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 660us/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 667us/step - loss: 0.0061 - val_loss: 0.0066\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 651us/step - loss: 0.0059 - val_loss: 0.0064\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 672us/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 676us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 686us/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 676us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 672us/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 676us/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 670us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 655us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 670us/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 658us/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 658us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 657us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 686us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 723us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 692us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 705us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 667us/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 678us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 663us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 679us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 690us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 677us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 678us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 687us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 680us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 669us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 684us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 707us/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 702us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 681us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 694us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 706us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 714us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 703us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 697us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 701us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 695us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 689us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 687us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 679us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 679us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 696us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 691us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 671us/step - loss: 0.0039 - val_loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 671us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 659us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 671us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 672us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 675us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 678us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 678us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 683us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 675us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 676us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 683us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 670us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 668us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 672us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 671us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 742us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 667us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 675us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 686us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 685us/step - loss: 0.0037 - val_loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=25))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "sgd = SGD(lr=0.1)\n",
    "model.compile(sgd, loss='mean_squared_error')\n",
    "history = model.fit(training_x, training_y, validation_data=(validation_x, validation_y), validation_steps=10, steps_per_epoch=44, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 530us/step\n",
      "MSE: 0.00344710\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: %.8f\" % model.evaluate(test_x, test_y, steps=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = onehot_data[0:750, :]\n",
    "training_y = targets[0:750]\n",
    "validation_x = onehot_data[750:1000, :]\n",
    "validation_y = targets[750:1000]\n",
    "test_x = onehot_data[1000:, :]\n",
    "test_y = targets[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
